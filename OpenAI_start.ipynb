{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "838d7c5f",
   "metadata": {},
   "source": [
    "important link: \n",
    "\n",
    "https://platform.openai.com/docs/quickstart/build-your-application\n",
    "\n",
    "Github page: https://github.com/openai/openai-python\n",
    "\n",
    "help(openai.Completion): see the word document in the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f92f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "# website to generate the key: https://platform.openai.com/account/api-keys\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "261993e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# question examples \n",
    "que_ex = pd.read_csv(\"que_exa.csv\")\n",
    "\n",
    "# extract columns\n",
    "snippets = que_ex['Article_Snippet']\n",
    "questions = que_ex['Question']\n",
    "answers = que_ex['Answer']\n",
    "distractors = que_ex['Distractors']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28ef68fe",
   "metadata": {},
   "source": [
    "Quick exmaple about how completion works. Also, I find \"temperature\" interesting. More variable details can be found here: https://platform.openai.com/docs/api-reference/completions/create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4d82472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hello, World! My name is <insert name here> and I'm happy to meet you.\n",
      "\n",
      "\n",
      "Hello! Welcome to the world!\n"
     ]
    }
   ],
   "source": [
    "# create a completion with high temperature\n",
    "completion = openai.Completion.create(model=\"text-davinci-003\", prompt=\"Hello world\", max_tokens=45, temperature=0.9)\n",
    "\n",
    "# print the completion\n",
    "print(completion.choices[0].text)\n",
    "\n",
    "\n",
    "# create a completion w/ low temperature\n",
    "completion = openai.Completion.create(model=\"text-davinci-003\", prompt=\"Hello world\", max_tokens=45, temperature=0)\n",
    "\n",
    "# print the completion\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07ba080b",
   "metadata": {},
   "source": [
    "Let's try with the first five snippets we already have\n",
    "\n",
    "Note here: when using text-davinci-003 model, frequently encoutered the bug: RateLimitError: The server had an error while processing your request. Sorry about that!\n",
    "\n",
    "Seems that in these days many people are facing the same issue, so I prefer to consider it as a bug of OpenAI and suggest waiting to see what's going on. https://community.openai.com/t/ratelimiterror-the-server-had-an-error-with-no-reason-given/50146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90b6c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly, let's create a help function to convert the snippet into the prompt format we want\n",
    "def help_convert(sentence):\n",
    "    return \"Snippet: \"+sentence+\"\\n Question: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a9e532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 0th snippet: \n",
      "OpenAI: \n",
      "\n",
      "What are the figures for mobile-phone subscriptions in India?\n",
      "W/ human supervise: \n",
      "How many mobile phone subscriptions were there in India in 2012, according to Chetan Sharma Consulting?\n",
      "------------------------------------------\n",
      "For 1th snippet: \n",
      "OpenAI: \n",
      "\n",
      "What was the main finding of the personal finance website study?\n",
      "W/ human supervise: \n",
      "How much did spending drop due to the government shutdown, according to data collected from a personal finance website?\n",
      "------------------------------------------\n",
      "For 2th snippet: \n",
      "OpenAI: \n",
      "\n",
      "What is the main point of the passage?\n",
      "W/ human supervise: \n",
      "How much does America's tax system reduce inequality relative to countries such as Canada and Sweden?\n",
      "------------------------------------------\n",
      "For 3th snippet: \n",
      "OpenAI: \n",
      "\n",
      "What is the correlation between the economic weight of government and the difference in countries' Gini coefficients after taxes and transfers?\n",
      "W/ human supervise: \n",
      "How does the economic weight of government correlate to the difference in countries' Gini coefficients after taxes and transfers?\n",
      "------------------------------------------\n",
      "For 4th snippet: \n",
      "OpenAI: \n",
      "\n",
      "What is the main difference between South Korea and other countries with low pre-tax inequality?\n",
      "W/ human supervise: \n",
      "How is South Korea able to achieve low post-tax inequality without much redistribution?\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "quick_train = list(snippets[50:55])\n",
    "generated = list(questions[50:55])\n",
    "\n",
    "for i in [0,1,2,3,4]:\n",
    "    print(\"For \"+str(i)+\"th snippet: \")\n",
    "    completion = openai.Completion.create(model=\"text-davinci-001\", prompt=help_convert(quick_train[i]), max_tokens=30)\n",
    "    print(\"OpenAI: \"+completion.choices[0].text)\n",
    "    print(\"W/ human supervise: \\n\"+generated[i])\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83c85e26",
   "metadata": {},
   "source": [
    "Looks good! (maybe?) Then let's see whether we can try training our own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94879882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1e220e357445836402dc3051b6e73f8807b0d2d9a8ef58cec3298c934ea7d9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
